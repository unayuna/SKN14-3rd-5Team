# data_preprocessor.py (ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ê°•í™” ë²„ì „)

import os
import json
from langchain_core.documents import Document
import pickle

JSON_DATA_DIR = "./01_data_preprocessing/json"
OUTPUT_FILE = "./01_data_preprocessing/faiss/preprocessed_documents.pkl"

def process_json_data():
    all_documents = []
    print(f"--- '{JSON_DATA_DIR}' í´ë”ì˜ JSON íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ---")
    if not os.path.exists(JSON_DATA_DIR):
        print(f"[ì˜¤ë¥˜] '{JSON_DATA_DIR}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    for filename in os.listdir(JSON_DATA_DIR):
        if filename.endswith(".json"):
            filepath = os.path.join(JSON_DATA_DIR, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # [í•µì‹¬ ìˆ˜ì •] question_idëŠ” JSON íŒŒì¼ ì•ˆì˜ ê°’ì„ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            question_id = data.get("question_id")
            if not question_id:
                print(f"[ê²½ê³ ] {filename}ì— 'question_id'ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                question_id = filename.replace(".json", "")

            # [í•µì‹¬ ìˆ˜ì •] ë©”íƒ€ë°ì´í„°ëŠ” íŒŒì¼ëª…ì´ ì•„ë‹Œ, question_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
            # ì˜ˆ: "2023_ì„œê°•ëŒ€_1" -> parts = ['2023', 'ì„œê°•ëŒ€', '1']
            parts = filename.replace(".json", "").split('_')
            
            # ë©”íƒ€ë°ì´í„° ìƒì„± ì‹œ, ì˜ˆì™¸ ìƒí™©ì— ëŒ€í•œ ë°©ì–´ ì½”ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            # íŒŒì¼ëª… êµ¬ì¡°ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜
            university = parts[0] if len(parts) > 0 else "ì•Œìˆ˜ì—†ìŒ"
            year = parts[1] if len(parts) > 1 else "ì•Œìˆ˜ì—†ìŒ"
            number = parts[2] if len(parts) > 2 else "ê¸°íƒ€"

            base_metadata = {
                "question_id": question_id,
                "university": university,
                "year": year,
                "number": number
            }

            content_map = {
                "ì¶œì œì˜ë„": data.get("intended_purpose"),
                "ì±„ì ê¸°ì¤€": data.get("grading_criteria"),
                "ëª¨ë²”ë‹µì•ˆ": data.get("sample_answer")
            }
            
            for content_type, content in content_map.items():
                if content:
                    doc_metadata = base_metadata.copy()
                    doc_metadata["source_type"] = content_type
                    all_documents.append(Document(page_content=content, metadata=doc_metadata))
            print(f"âœ… {filename} ì²˜ë¦¬ ì™„ë£Œ. (ID: {question_id})")

    if not all_documents:
        print("[ê²½ê³ ] ì²˜ë¦¬í•  ë¬¸ì„œê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        return None

    with open(OUTPUT_FILE, 'wb') as f:
        pickle.dump(all_documents, f)
    print(f"\nğŸ‰ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œ ì¡°ê°ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return all_documents

if __name__ == '__main__':
    processed_data = process_json_data()
    if processed_data:
        print("\n[ìƒ˜í”Œ ë°ì´í„° í™•ì¸]")
        for doc in processed_data[:5]:
            print(doc, "\n" + "-"*30)