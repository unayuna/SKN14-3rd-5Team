import streamlit as st
from dotenv import load_dotenv
import os

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = openai_key

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
import tempfile

st.title("ğŸ“š PDF ê¸°ë°˜ RAG Q&A ì‹œìŠ¤í…œ")

uploaded_file = st.file_uploader("PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        pdf_path = tmp_file.name

    st.success("PDF ë¡œë”© ì™„ë£Œ")

    if st.button("ğŸ” ë¬¸ì„œ ë²¡í„°í™” ì‹œì‘"):
        loader = PyPDFLoader(pdf_path)
        docs = loader.load()

        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        split_docs = splitter.split_documents(docs)

        embeddings = OpenAIEmbeddings()
        vectordb = Chroma.from_documents(split_docs, embedding=embeddings)

        st.session_state.vectordb = vectordb
        st.success("âœ… ë²¡í„°í™” ì™„ë£Œ")

if "vectordb" in st.session_state:
    user_question = st.text_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

    if user_question:
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)  # ë˜ëŠ” gpt-4
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=st.session_state.vectordb.as_retriever()
        )

        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            answer = qa_chain.run(user_question)

        st.markdown("### ğŸ“¢ ë‹µë³€:")
        st.write(answer)
