import os
import json
from dotenv import load_dotenv

from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

load_dotenv(dotenv_path="../essay_test/.env")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-ada-002")
DATA_DIR = "../essay_test/data"



def load_data():
    all_data = {}
    for fname in os.listdir(DATA_DIR):
        if fname.endswith(".json"):
            with open(os.path.join(DATA_DIR, fname), "r", encoding="utf-8") as f:
                data = json.load(f)
            qid = data["question_id"]
            year, school, qnum = qid.split("_", 2)
            all_data[qid] = {
                "year": year,
                "school": school,
                "qnum": qnum,
                "data": data,
                "file": fname
            }
    return all_data



def build_vectorstore(question_bank):
    docs = []
    for qid, item in question_bank.items():
        content = f"ì§ˆë¬¸ ID: {qid}\n"
        content += f"[ì¶œì œ ëª©ì ]\n{item['data'].get('intended_purpose')}\n\n"
        content += f"[ì±„ì  ê¸°ì¤€]\n{item['data'].get('grading_criteria')}\n\n"
        content += f"[ì˜ˆì‹œ ë‹µì•ˆ]\n{item['data'].get('sample_answer')}"
        doc = Document(page_content=content, metadata={"question_id": qid})
        docs.append(doc)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=OPENAI_EMBEDDING_MODEL)
    return FAISS.from_documents(splits, embeddings)


def generate_feedback(llm, question_id, grading_criteria, sample_answer, user_answer, vectorstore):
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3, "filter": {"question_id": question_id}}
    )
    docs = retriever.get_relevant_documents("")
    context = "\n\n".join([doc.page_content for doc in docs])

    prompt = f"""
[ì—­í• ]
ë‹¹ì‹ ì€ ëŒ€ì¹˜ë™ì—ì„œ 10ë…„ê°„ ë…¼ìˆ ì„ ê°€ë¥´ì¹œ, ëƒ‰ì² í•˜ì§€ë§Œ ì• ì • ì–´ë¦° ì¡°ì–¸ì„ ì•„ë¼ì§€ ì•ŠëŠ” ìŠ¤íƒ€ê°•ì‚¬ 'ë…¼ë¦¬ì™• ê¹€ë©˜í† 'ì…ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]
1. [ì±„ì  ê¸°ì¤€]: {grading_criteria}
2. [ëª¨ë²” ë‹µì•ˆ]: {sample_answer}
3. [í•™ìƒ ë‹µì•ˆ]: {user_answer}

[ì²¨ì‚­ ì ˆì°¨ ë° ì§€ì‹œ]
1. (ì´í•´) í•™ìƒ ë‹µì•ˆì„ ì „ì²´ì ìœ¼ë¡œ ì½ê³  í•µì‹¬ ì£¼ì¥ íŒŒì•…
2. (ë¹„êµ) ì±„ì  ê¸°ì¤€ ë° ì˜ˆì‹œë‹µì•ˆê³¼ ë¹„êµí•˜ì—¬ ë¶„ì„
3. (í‰ê°€) ì¥ë‹¨ì  ëª…ì‹œ
4. (ì¢…í•©) ì²¨ì‚­ ë¬¸ì¥ ì™„ì„±

[ì¶œë ¥ í˜•ì‹]
---
**[ì´í‰]**
...

**[ì˜í•œ ì  (ì¹­ì°¬ í¬ì¸íŠ¸) ğŸ‘]**
...

**[ì•„ì‰¬ìš´ ì  (ê°œì„  í¬ì¸íŠ¸) âœï¸]**
...

**[ì´ë ‡ê²Œ ë°”ê¿”ë³´ì„¸ìš” (ëŒ€ì•ˆ ë¬¸ì¥ ì œì•ˆ) ğŸ’¡]**
...

**[ì˜ˆìƒ ì ìˆ˜ ë° ë‹¤ìŒ í•™ìŠµ íŒ ğŸš€]**
...
"""
    result = llm.invoke(prompt)
    return result.content


def build_answer_chatbot(user_answer):
    doc = Document(page_content=user_answer)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    splits = text_splitter.split_documents([doc])
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=OPENAI_EMBEDDING_MODEL)
    return FAISS.from_documents(splits, embeddings)