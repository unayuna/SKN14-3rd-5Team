import streamlit as st
from rag import AnswerChatRAG
from rag import load_data, build_vectorstore, generate_feedback
from langchain.chat_models import ChatOpenAI
from rag import OPENAI_API_KEY
from langchain_core.output_parsers import StrOutputParser


st.title("ğŸ“ RAG ê¸°ë°˜ ë…¼ìˆ  ì²¨ì‚­ ë„ìš°ë¯¸")

question_bank = load_data()

# í•„í„° ì˜µì…˜ ìƒì„±
schools = sorted(set(d["school"] for d in question_bank.values()))
selected_school = st.selectbox("í•™êµ ì„ íƒ", schools)

years = sorted(set(d["year"] for d in question_bank.values() if d["school"] == selected_school))
selected_year = st.selectbox("ì—°ë„ ì„ íƒ", years)

qnums = sorted(set(d["qnum"] for d in question_bank.values()
                   if d["school"] == selected_school and d["year"] == selected_year))
selected_qnum = st.selectbox("ë¬¸í•­ ë²ˆí˜¸", qnums)

# question_id ì¡°í•©
selected_qid = f"{selected_year}_{selected_school}_{selected_qnum}"
selected_entry = question_bank.get(selected_qid)

if selected_entry:
    data = selected_entry["data"]
    question_id = data["question_id"]
    intended_purpose = data["intended_purpose"]
    grading_criteria = data["grading_criteria"]
    sample_answer = data["sample_answer"]

    llm = ChatOpenAI(model="gpt-4", temperature=0, openai_api_key=OPENAI_API_KEY)
    parser = StrOutputParser()

    # ë¬¸í•­ ì •ë³´ ì¶œë ¥
    with st.expander("ğŸ“˜ ë¬¸í•­ ì •ë³´ ì—´ê¸°"):
        st.markdown(f"**ë¬¸í•­ ID:** `{question_id}`")
        st.markdown("**ì¶œì œ ì˜ë„:**")
        st.write(intended_purpose)
        st.markdown("**ì±„ì  ê¸°ì¤€:**")
        st.write(grading_criteria)
        st.markdown("**ì˜ˆì‹œ ë‹µì•ˆ:**")
        st.write(sample_answer)

    # ì‚¬ìš©ì ë‹µì•ˆ ìƒíƒœ ìœ ì§€
    if "user_answer" not in st.session_state:
        st.session_state.user_answer = ""
    if "feedback_button_clicked" not in st.session_state:
        st.session_state.feedback_button_clicked = False
    if "feedback_result" not in st.session_state:
        st.session_state.feedback_result = ""

    # ì‚¬ìš©ì ì…ë ¥
    user_answer = st.text_area("âœï¸ ë‚˜ì˜ ë‹µì•ˆ ì…ë ¥", height=300)
    st.session_state.user_answer = user_answer

    if st.button("ğŸ“Š ì²¨ì‚­ ë°›ê¸°") and user_answer.strip():
        st.session_state.feedback_button_clicked = True
        with st.spinner("AIê°€ ì²¨ì‚­ ì¤‘ì…ë‹ˆë‹¤..."):
            llm = ChatOpenAI(model="gpt-4", temperature=0)
            vectorstore = build_vectorstore(question_bank)
            result = generate_feedback(
                llm,
                question_id=data["question_id"],
                grading_criteria=data["grading_criteria"],
                sample_answer=data["sample_answer"],
                user_answer=user_answer,
                vectorstore=vectorstore
            )
            st.subheader("ğŸ“‹ ì²¨ì‚­ ê²°ê³¼")
            st.markdown(result)

    st.markdown("---")
    st.subheader("ğŸ§  ë‚´ ë‹µë³€ ê¸°ë°˜ Q&A ì±—ë´‡")

    # if user_answer.strip():
    #     vectorstore = build_vectorstore(user_answer)
    #     user_q = st.chat_input("ë‚´ ë‹µë³€ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
    #
    #     if "answer_chat_history" not in st.session_state:
    #         st.session_state.answer_chat_history = []
    #
    #     # ì´ì „ ì±„íŒ… ê¸°ë¡ ì¶œë ¥
    #     for msg in st.session_state.answer_chat_history:
    #         with st.chat_message(msg["role"]):
    #             st.markdown(msg["content"])
    #
    #     if user_q:
    #         st.session_state.answer_chat_history.append({"role": "user", "content": user_q})
    #         with st.chat_message("user"):
    #             st.markdown(user_q)
    #
    #         chain = build_chain(vectorstore, openai_api_key=OPENAI_API_KEY)
    #
    #         # ì‘ë‹µ ìƒì„±
    #         with st.chat_message("assistant"):
    #             with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
    #                 output = chain.invoke({"question": user_q})
    #                 st.markdown(output)
    #                 st.session_state.answer_chat_history.append({"role": "assistant", "content": output})

    from rag import AnswerChatRAG

    if user_answer.strip():
        rag = AnswerChatRAG(user_answer, openai_api_key=OPENAI_API_KEY)
        user_q = st.chat_input("ë‚´ ë‹µë³€ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

        if "answer_chat_history" not in st.session_state:
            st.session_state.answer_chat_history = []

        # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
        for msg in st.session_state.answer_chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if user_q:
            st.session_state.answer_chat_history.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)

            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    output = rag.invoke(user_q)
                    st.markdown(output)
                    st.session_state.answer_chat_history.append({"role": "assistant", "content": output})

    else:
        st.info("ë¨¼ì € ë‹µì•ˆì„ ì…ë ¥í•˜ì„¸ìš”.")
