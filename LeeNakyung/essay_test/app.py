import streamlit as st
from rag import load_data, build_vectorstore, generate_feedback, build_answer_chatbot
from langchain.chat_models import ChatOpenAI
from rag import OPENAI_API_KEY
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import PromptTemplate

st.title("ğŸ“ RAG ê¸°ë°˜ ë…¼ìˆ  ì²¨ì‚­ ë„ìš°ë¯¸")

question_bank = load_data()

# í•„í„° ì˜µì…˜ ìƒì„±
schools = sorted(set(d["school"] for d in question_bank.values()))
selected_school = st.selectbox("í•™êµ ì„ íƒ", schools)

years = sorted(set(d["year"] for d in question_bank.values() if d["school"] == selected_school))
selected_year = st.selectbox("ì—°ë„ ì„ íƒ", years)

qnums = sorted(set(d["qnum"] for d in question_bank.values()
                   if d["school"] == selected_school and d["year"] == selected_year))
selected_qnum = st.selectbox("ë¬¸í•­ ë²ˆí˜¸", qnums)

# question_id ì¡°í•©
selected_qid = f"{selected_year}_{selected_school}_{selected_qnum}"
selected_entry = question_bank.get(selected_qid)

if selected_entry:
    data = selected_entry["data"]
    question_id = data["question_id"]
    intended_purpose = data["intended_purpose"]
    grading_criteria = data["grading_criteria"]
    sample_answer = data["sample_answer"]

    llm = ChatOpenAI(model="gpt-4", temperature=0, openai_api_key=OPENAI_API_KEY)
    parser = StrOutputParser()

    # ë¬¸í•­ ì •ë³´ ì¶œë ¥
    with st.expander("ğŸ“˜ ë¬¸í•­ ì •ë³´ ì—´ê¸°"):
        st.markdown(f"**ë¬¸í•­ ID:** `{question_id}`")
        st.markdown("**ì¶œì œ ì˜ë„:**")
        st.write(intended_purpose)
        st.markdown("**ì±„ì  ê¸°ì¤€:**")
        st.write(grading_criteria)
        st.markdown("**ì˜ˆì‹œ ë‹µì•ˆ:**")
        st.write(sample_answer)

    # ì‚¬ìš©ì ë‹µì•ˆ ìƒíƒœ ìœ ì§€
    if "user_answer" not in st.session_state:
        st.session_state.user_answer = ""
    if "feedback_button_clicked" not in st.session_state:
        st.session_state.feedback_button_clicked = False
    if "feedback_result" not in st.session_state:
        st.session_state.feedback_result = ""

    # ì‚¬ìš©ì ì…ë ¥
    user_answer = st.text_area("âœï¸ ë‚˜ì˜ ë‹µì•ˆ ì…ë ¥", height=300)
    st.session_state.user_answer = user_answer

    if st.button("ğŸ“Š ì²¨ì‚­ ë°›ê¸°") and user_answer.strip():
        st.session_state.feedback_button_clicked = True
        with st.spinner("AIê°€ ì²¨ì‚­ ì¤‘ì…ë‹ˆë‹¤..."):
            llm = ChatOpenAI(model="gpt-4", temperature=0)
            vectorstore = build_vectorstore(question_bank)
            result = generate_feedback(
                llm,
                question_id=data["question_id"],
                grading_criteria=data["grading_criteria"],
                sample_answer=data["sample_answer"],
                user_answer=user_answer,
                vectorstore=vectorstore
            )
            st.subheader("ğŸ“‹ ì²¨ì‚­ ê²°ê³¼")
            st.markdown(result)

    st.markdown("---")
    st.subheader("ğŸ§  ë‚´ ë‹µë³€ ê¸°ë°˜ Q&A ì±—ë´‡")

    if user_answer.strip():
        vectorstore = build_answer_chatbot(user_answer)
        user_q = st.chat_input("ë‚´ ë‹µë³€ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

        if "answer_chat_history" not in st.session_state:
            st.session_state.answer_chat_history = []

        # ì´ì „ ì±„íŒ… ê¸°ë¡ ì¶œë ¥
        for msg in st.session_state.answer_chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if user_q:
            st.session_state.answer_chat_history.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)

            retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

            # ì²´ì¸ êµ¬ì„±
            prompt = PromptTemplate.from_template("""
            ë‹¹ì‹ ì€ 10ë…„ ì´ìƒ ìˆ˜ëŠ¥ ë° ëŒ€í•™ ë…¼ìˆ ì„ ì „ë¬¸ì ìœ¼ë¡œ ê°€ë¥´ì³ì˜¨ ì²¨ì‚­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•™ìƒì´ ì‘ì„±í•œ ë…¼ìˆ  ë¬¸ì¥ì„ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.
            
            [ì œì‹œ ë¬¸ì¥]
            ì•„ë˜ëŠ” ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ì„ íƒëœ í•™ìƒì˜ ë‹µì•ˆ ë‚´ìš© ì¼ë¶€ì…ë‹ˆë‹¤. ì°¸ê³ í•´ ë¶„ì„ì— í™œìš©í•˜ì„¸ìš”.
            
            {context}
            
            [í•™ìƒ ì§ˆë¬¸]
            {question}
            
            [ë‹µë³€ ì§€ì¹¨]
            1. ì§ˆë¬¸ì˜ ìš”ì§€ë¥¼ íŒŒì•…í•˜ê³ , ë‹µì•ˆ ë¬¸ì¥ ì¤‘ ê´€ë ¨ ìˆëŠ” ë‚´ìš©ì„ ì—°ê²°í•´ í•´ì„í•©ë‹ˆë‹¤.
            2. ë¶€ì¡±í•˜ê±°ë‚˜ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  êµ¬ì²´ì ì¸ ë¬¸ì¥ ë˜ëŠ” ë°©í–¥ì„ ì œì•ˆí•©ë‹ˆë‹¤.
            3. í”¼ë“œë°±ì€ ì¹œì ˆí•˜ê³  ì¡°ë¦¬ ìˆê²Œ ì œì‹œí•˜ë˜, ë…¼ë¦¬ì„±ê³¼ êµ¬ì¡°ì  ì‚¬ê³ ë ¥ì„ ê¸°ë¥¼ ìˆ˜ ìˆë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
            
            [ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ]
            - ë¶„ì„: â€¦
            - ê°•ì : â€¦
            - ë³´ì™„ì : â€¦
            - ê°œì„  ì œì•ˆ: â€¦
            
            [ë‹µë³€]
            """)

            chain = (
                    {
                        "context": lambda x: "\n\n".join([
                            doc.page_content for doc in retriever.get_relevant_documents(x["question"])
                        ]),
                        "question": lambda x: x["question"]
                    }
                    | prompt
                    | ChatOpenAI(model="gpt-4", temperature=0, openai_api_key=OPENAI_API_KEY)
                    | StrOutputParser()
            )

            # ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    output = chain.invoke({"question": user_q})
                    st.markdown(output)
                    st.session_state.answer_chat_history.append({"role": "assistant", "content": output})
    else:
        st.info("ë¨¼ì € ë‹µì•ˆì„ ì…ë ¥í•˜ì„¸ìš”.")
