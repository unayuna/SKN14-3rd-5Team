import streamlit as st
from rag import AnswerChatRAG
from rag import load_data, build_vectorstore, generate_feedback, extract_text_from_image
from langchain.chat_models import ChatOpenAI
from rag import OPENAI_API_KEY
from langchain_core.output_parsers import StrOutputParser


st.title("ğŸ“ RAG ê¸°ë°˜ ë…¼ìˆ  ì²¨ì‚­ ë„ìš°ë¯¸")

question_bank = load_data()

# í•„í„° ì˜µì…˜ ìƒì„±
schools = sorted(set(d["school"] for d in question_bank.values()))
selected_school = st.selectbox("í•™êµ ì„ íƒ", schools)

years = sorted(set(d["year"] for d in question_bank.values() if d["school"] == selected_school))
selected_year = st.selectbox("ì—°ë„ ì„ íƒ", years)

qnums = sorted(set(d["qnum"] for d in question_bank.values()
                   if d["school"] == selected_school and d["year"] == selected_year))
selected_qnum = st.selectbox("ë¬¸í•­ ë²ˆí˜¸", qnums)

# question_id ì¡°í•©
selected_qid = f"{selected_year}_{selected_school}_{selected_qnum}"
selected_entry = question_bank.get(selected_qid)

if selected_entry:
    data = selected_entry["data"]
    question_id = data["question_id"]
    intended_purpose = data["intended_purpose"]
    grading_criteria = data["grading_criteria"]
    sample_answer = data["sample_answer"]

    llm = ChatOpenAI(model="gpt-4", temperature=0, openai_api_key=OPENAI_API_KEY)
    parser = StrOutputParser()

    # ë¬¸í•­ ì •ë³´ ì¶œë ¥
    with st.expander("ğŸ“˜ ë¬¸í•­ ì •ë³´ ì—´ê¸°"):
        st.markdown(f"**ë¬¸í•­ ID:** `{question_id}`")
        st.markdown("**ì¶œì œ ì˜ë„:**")
        st.write(intended_purpose)
        st.markdown("**ì±„ì  ê¸°ì¤€:**")
        st.write(grading_criteria)
        st.markdown("**ì˜ˆì‹œ ë‹µì•ˆ:**")
        st.write(sample_answer)

    # ì‚¬ìš©ì ë‹µì•ˆ ìƒíƒœ ìœ ì§€
    if "user_answer" not in st.session_state:
        st.session_state.user_answer = ""
    if "feedback_button_clicked" not in st.session_state:
        st.session_state.feedback_button_clicked = False
    if "feedback_result" not in st.session_state:
        st.session_state.feedback_result = ""

    # ì‚¬ìš©ì ì…ë ¥
    # st.subheader("ğŸ“· ì†ê¸€ì”¨ ë‹µì•ˆ ì—…ë¡œë“œ (OCR ì¸ì‹)")
    #
    # uploaded_image = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
    #
    # if uploaded_image is not None:
    #     st.image(uploaded_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
    #
    #     if st.button("ğŸ§  í…ìŠ¤íŠ¸ ì¶”ì¶œ"):
    #         with st.spinner("OCR ì²˜ë¦¬ ì¤‘..."):
    #             extracted_text = extract_text_from_image(uploaded_image)
    #             st.success("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
    #             st.text_area("ğŸ“ ì¶”ì¶œëœ ë‹µì•ˆ", value=extracted_text, height=300, key="ocr_answer")
    #             st.session_state.user_answer = extracted_text

    user_answer = st.text_area("âœï¸ ë‚˜ì˜ ë‹µì•ˆ ì…ë ¥", height=300)
    st.session_state.user_answer = user_answer

    if st.button("ğŸ“Š ì²¨ì‚­ ë°›ê¸°") and user_answer.strip():
        st.session_state.feedback_button_clicked = True
        with st.spinner("AIê°€ ì²¨ì‚­ ì¤‘ì…ë‹ˆë‹¤..."):
            llm = ChatOpenAI(model="gpt-4", temperature=0)
            vectorstore = build_vectorstore(question_bank)
            result = generate_feedback(
                llm,
                question_id=data["question_id"],
                grading_criteria=data["grading_criteria"],
                sample_answer=data["sample_answer"],
                user_answer=user_answer,
                vectorstore=vectorstore
            )
            st.subheader("ğŸ“‹ ì²¨ì‚­ ê²°ê³¼")
            st.markdown(result)

    st.markdown("---")
    st.subheader("ğŸ§  ë‚´ ë‹µë³€ ê¸°ë°˜ Q&A ì±—ë´‡")

    faq_questions = [
        "ë‚´ ì£¼ì¥ì˜ ë…¼ë¦¬ ì „ê°œê°€ ê´œì°®ì€ê°€ìš”?",
        "ë” ì„¤ë“ë ¥ ìˆê²Œ ì“°ë ¤ë©´ ì–´ë–¤ í‘œí˜„ì„ ì“°ë©´ ì¢‹ì„ê¹Œìš”?",
        "ê²°ë¡  ë¶€ë¶„ì„ ì–´ë–»ê²Œ ë³´ì™„í•  ìˆ˜ ìˆì„ê¹Œìš”?",
        "ì˜ˆì‹œê°€ ë¶€ì¡±í•œê°€ìš”?",
        "ë¬¸ì¥ì´ ë„ˆë¬´ í‰ë²”í•œê°€ìš”? ì¸ìƒ ê¹Šê²Œ ê³ ì¹˜ëŠ” ë°©ë²•ì€?"
    ]

    st.markdown("#### ğŸ“Œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸")
    for i, question in enumerate(faq_questions):
        if st.button(question, key=f"faq_{i}"):
            st.session_state["faq_clicked"] = question

    if user_answer.strip():
        rag = AnswerChatRAG(user_answer, openai_api_key=OPENAI_API_KEY)
        user_q = st.chat_input("ë‚´ ë‹µë³€ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

        if "faq_clicked" in st.session_state and st.session_state["faq_clicked"]:
            user_q = st.session_state["faq_clicked"]
            st.session_state["faq_clicked"] = ""

        if "answer_chat_history" not in st.session_state:
            st.session_state.answer_chat_history = []

        # ì´ì „ ì±„íŒ… ê¸°ë¡ ì¶œë ¥
        for msg in st.session_state.answer_chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if user_q:
            st.session_state.answer_chat_history.append({"role": "user", "content": user_q})
            with st.chat_message("user"):
                st.markdown(user_q)

            # ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    output = rag.invoke(user_q)
                    st.markdown(output)
                    st.session_state.answer_chat_history.append({"role": "assistant", "content": output})

    else:
        st.info("ë¨¼ì € ë‹µì•ˆì„ ì…ë ¥í•˜ì„¸ìš”.")
